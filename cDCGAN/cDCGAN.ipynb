{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataloader import default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelD, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, 1, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, 1, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.fc1  = nn.Linear(64*28*28+1000, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1)\n",
    "        self.fc3 = nn.Linear(10, 1000)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, 1, 28,28)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(batch_size, 64*28*28)\n",
    "        y_ = self.fc3(labels)\n",
    "        y_ = F.relu(y_)\n",
    "        x = torch.cat([x, y_], 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "class ModelG(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        self.z_dim = z_dim\n",
    "        super(ModelG, self).__init__()\n",
    "        self.fc2 = nn.Linear(10, 1000)\n",
    "        self.fc = nn.Linear(self.z_dim+1000, 64*28*28)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.deconv1 = nn.ConvTranspose2d(64, 32, 5, 1, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.deconv2 = nn.ConvTranspose2d(32, 1, 5, 1, 2)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        batch_size = x.size(0)\n",
    "        y_ = self.fc2(labels)\n",
    "        y_ = F.relu(y_)\n",
    "        x = torch.cat([x, y_], 1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(batch_size, 64, 28, 28)\n",
    "        x = self.bn1(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.01\n",
    "epochs = 10\n",
    "nz = 100\n",
    "save_every = 1\n",
    "save_dir = 'models_latest'\n",
    "samples_dir = 'samples_latest'\n",
    "cuda = True\n",
    "print_every = 50\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "if not os.path.exists(samples_dir):\n",
    "    os.mkdir(samples_dir)\n",
    "\n",
    "INPUT_SIZE = 784\n",
    "SAMPLE_SIZE = 80\n",
    "NUM_LABELS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [115 x 9], m2: [10 x 1000] at /opt/conda/conda-bld/pytorch_1549636813070/work/aten/src/THC/generic/THCTensorMathBlas.cu:266",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-ea2a985e4c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mlabelv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0moptim_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0merrD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a98b0a8587d2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, labels)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [115 x 9], m2: [10 x 1000] at /opt/conda/conda-bld/pytorch_1549636813070/work/aten/src/THC/generic/THCTensorMathBlas.cu:266"
     ]
    }
   ],
   "source": [
    "def my_collate(batch):\n",
    "    modified_batch = []\n",
    "    for item in batch:\n",
    "        image, label = item\n",
    "        if label is not 9:\n",
    "            modified_batch.append(item)\n",
    "    return default_collate(modified_batch)\n",
    "\n",
    "# data_loader\n",
    "# img_size = 32\n",
    "transform = transforms.Compose([\n",
    "#         transforms.Scale(img_size),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transform),\n",
    "                   batch_size=128, shuffle=True, collate_fn = my_collate)\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='data',\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=transforms.ToTensor())\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, shuffle=True,\n",
    "#     batch_size=batch_size)\n",
    "\n",
    "model_d = ModelD()\n",
    "model_g = ModelG(nz)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "input = torch.FloatTensor(batch_size, INPUT_SIZE)\n",
    "noise = torch.FloatTensor(batch_size, (nz))\n",
    "\n",
    "fixed_noise = torch.FloatTensor(SAMPLE_SIZE, nz).normal_(0,1)\n",
    "fixed_labels = torch.zeros(SAMPLE_SIZE, NUM_LABELS)\n",
    "\n",
    "for i in range(NUM_LABELS):\n",
    "    for j in range(SAMPLE_SIZE // NUM_LABELS):\n",
    "        fixed_labels[i*(SAMPLE_SIZE // NUM_LABELS) + j, i] = 1.0\n",
    "\n",
    "label = torch.FloatTensor(batch_size)\n",
    "one_hot_labels = torch.FloatTensor(batch_size, 10)\n",
    "\n",
    "if cuda:\n",
    "    model_d.cuda()\n",
    "    model_g.cuda()\n",
    "    input, label = input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "    one_hot_labels = one_hot_labels.cuda()\n",
    "    fixed_labels = fixed_labels.cuda()\n",
    "\n",
    "optim_d = optim.SGD(model_d.parameters(), lr=lr)\n",
    "optim_g = optim.SGD(model_g.parameters(), lr=lr)\n",
    "fixed_noise = Variable(fixed_noise)\n",
    "fixed_labels = Variable(fixed_labels)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "for epoch_idx in range(epochs):\n",
    "    model_d.train()\n",
    "    model_g.train()\n",
    "\n",
    "    d_loss = 0.0\n",
    "    g_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (train_x, train_y) in enumerate(train_loader):\n",
    "        batch_size = train_x.size(0)\n",
    "        train_x = train_x.view(-1, INPUT_SIZE)\n",
    "        if cuda:\n",
    "            train_x = train_x.cuda()\n",
    "            train_y = train_y.cuda()\n",
    "\n",
    "        input.resize_as_(train_x).copy_(train_x)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "        one_hot_labels.resize_(batch_size, NUM_LABELS).zero_()\n",
    "        one_hot_labels.scatter_(1, train_y.view(batch_size,1), 1)\n",
    "        inputv = Variable(input)\n",
    "        labelv = Variable(label)\n",
    "\n",
    "        output = model_d(inputv, Variable(one_hot_labels))\n",
    "        optim_d.zero_grad()\n",
    "        errD_real = criterion(output, labelv)\n",
    "        errD_real.backward()\n",
    "        realD_mean = output.data.cpu().mean()\n",
    "\n",
    "        one_hot_labels.zero_()\n",
    "        rand_y = torch.from_numpy(\n",
    "            np.random.randint(0, NUM_LABELS, size=(batch_size,1))).cuda()\n",
    "        one_hot_labels.scatter_(1, rand_y.view(batch_size,1), 1)\n",
    "        noise.resize_(batch_size, nz).normal_(0,1)\n",
    "        label.resize_(batch_size).fill_(fake_label)\n",
    "        noisev = Variable(noise)\n",
    "        labelv = Variable(label)\n",
    "        onehotv = Variable(one_hot_labels)\n",
    "        g_out = model_g(noisev, onehotv)\n",
    "        output = model_d(g_out, onehotv)\n",
    "        errD_fake = criterion(output, labelv)\n",
    "        fakeD_mean = output.data.cpu().mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        errD_fake.backward()\n",
    "        optim_d.step()\n",
    "\n",
    "        # train the G\n",
    "        noise.normal_(0,1)\n",
    "        one_hot_labels.zero_()\n",
    "        rand_y = torch.from_numpy(\n",
    "            np.random.randint(0, NUM_LABELS, size=(batch_size,1))).cuda()\n",
    "        one_hot_labels.scatter_(1, rand_y.view(batch_size,1), 1)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "        onehotv = Variable(one_hot_labels)\n",
    "        noisev = Variable(noise)\n",
    "        labelv = Variable(label)\n",
    "        g_out = model_g(noisev, onehotv)\n",
    "        output = model_d(g_out, onehotv)\n",
    "        errG = criterion(output, labelv)\n",
    "        optim_g.zero_grad()\n",
    "        errG.backward()\n",
    "        optim_g.step()\n",
    "\n",
    "        d_loss += errD.data\n",
    "        g_loss += errG.data\n",
    "        if batch_idx % print_every == 0:\n",
    "            print(\n",
    "            \"\\t{} ({} / {}) mean D(fake) = {:.4f}, mean D(real) = {:.4f}\".\n",
    "                format(epoch_idx, batch_idx, len(train_loader), fakeD_mean,\n",
    "                    realD_mean))\n",
    "\n",
    "            g_out = model_g(fixed_noise, fixed_labels).data.view(\n",
    "                SAMPLE_SIZE, 1, 28,28).cpu()\n",
    "            save_image(g_out,\n",
    "                '{}/{}_{}.png'.format(\n",
    "                    samples_dir, epoch_idx, batch_idx))\n",
    "\n",
    "\n",
    "    print('Epoch {} - D loss = {:.4f}, G loss = {:.4f}'.format(epoch_idx,\n",
    "        d_loss, g_loss))\n",
    "    if epoch_idx % save_every == 0:\n",
    "        torch.save(model_d.state_dict(),\n",
    "                    '{}/model_d_epoch_{}.pkl'.format(\n",
    "                        save_dir, epoch_idx))\n",
    "        torch.save(model_g.state_dict(),\n",
    "                    '{}/model_g_epoch_{}.pkl'.format(\n",
    "                        save_dir, epoch_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Learning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelD(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=51176, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (fc3): Linear(in_features=10, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_model = ModelG(100)\n",
    "g_model.load_state_dict(torch.load(\"models/model_g_epoch_9.pkl\"))\n",
    "g_model.eval()\n",
    "\n",
    "d_model = ModelD()\n",
    "d_model.load_state_dict(torch.load(\"models/model_d_epoch_9.pkl\"))\n",
    "d_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelD(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=51176, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (fc3): Linear(in_features=10, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_model.cuda()\n",
    "d_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing parameters\n",
    "batch_size = 1\n",
    "# lr = 0.01\n",
    "# epoch = 10\n",
    "# INPUT_SIZE = 784\n",
    "\n",
    "# Getting some images of nine ready for inference:\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ColorJitter(),\n",
    "#         transforms.Scale(784),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='nine_data', train=True, download=True, transform=transform)\n",
    "\n",
    "idx = dataset.targets == 9\n",
    "\n",
    "dataset.data = dataset.data[idx]\n",
    "dataset.targets = dataset.targets[idx]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader._DataLoaderIter'>\n",
      "images shape on batch size = torch.Size([1, 1, 28, 28])\n",
      "labels shape on batch size = torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "print(type(train_iter))\n",
    "\n",
    "images, labels = train_iter.next()\n",
    "\n",
    "print('images shape on batch size = {}'.format(images.size()))\n",
    "print('labels shape on batch size = {}'.format(labels.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '[9]')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.title(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "tensor([9])\n",
      "tensor([9])\n",
      "tensor([9])\n",
      "tensor([9])\n",
      "tensor([9])\n"
     ]
    }
   ],
   "source": [
    "# see if train_loader is giving only nines\n",
    "print(type(train_loader))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for x_, y in train_loader:\n",
    "    count+= 1\n",
    "    # print(x_)\n",
    "    print(y)\n",
    "    if count == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data to be trained upon: around 200 images\n",
    "\n",
    "train_custom_data = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    count = 0\n",
    "    for item in train_loader:\n",
    "        train_custom_data.append(item)\n",
    "        count += 1\n",
    "        if count == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(train_custom_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0 (0 / 5949) mean D(fake) = 0.0000, mean D(real) = 1.0000\n",
      "Epoch 0 - D loss = 0.0557, G loss = 381.1879\n",
      "\t1 (0 / 5949) mean D(fake) = 0.0000, mean D(real) = 1.0000\n",
      "Epoch 1 - D loss = 0.0155, G loss = 373.5790\n",
      "\t2 (0 / 5949) mean D(fake) = 0.0000, mean D(real) = 1.0000\n",
      "Epoch 2 - D loss = 0.0446, G loss = 371.0468\n",
      "\t3 (0 / 5949) mean D(fake) = 0.0000, mean D(real) = 1.0000\n",
      "Epoch 3 - D loss = 0.1623, G loss = 356.7957\n",
      "\t4 (0 / 5949) mean D(fake) = 0.0000, mean D(real) = 1.0000\n",
      "Epoch 4 - D loss = 0.1008, G loss = 370.4163\n",
      "\t5 (0 / 5949) mean D(fake) = 0.0000, mean D(real) = 1.0000\n",
      "Epoch 5 - D loss = 0.0396, G loss = 373.4356\n",
      "\t6 (0 / 5949) mean D(fake) = 0.0000, mean D(real) = 1.0000\n",
      "Epoch 6 - D loss = 0.4512, G loss = 373.2437\n",
      "\t7 (0 / 5949) mean D(fake) = 0.0000, mean D(real) = 1.0000\n",
      "Epoch 7 - D loss = 4.2195, G loss = 287.3220\n",
      "\t8 (0 / 5949) mean D(fake) = 0.0000, mean D(real) = 1.0000\n",
      "Epoch 8 - D loss = 0.0325, G loss = 438.2352\n",
      "\t9 (0 / 5949) mean D(fake) = 0.0000, mean D(real) = 1.0000\n",
      "Epoch 9 - D loss = 0.1194, G loss = 347.7995\n"
     ]
    }
   ],
   "source": [
    "input = torch.FloatTensor(batch_size, INPUT_SIZE)\n",
    "noise = torch.FloatTensor(batch_size, (nz))\n",
    "\n",
    "fixed_noise = torch.FloatTensor(SAMPLE_SIZE, nz).normal_(0,1)\n",
    "fixed_labels = torch.zeros(SAMPLE_SIZE, NUM_LABELS)\n",
    "\n",
    "for i in range(NUM_LABELS):\n",
    "    for j in range(SAMPLE_SIZE // NUM_LABELS):\n",
    "        fixed_labels[i*(SAMPLE_SIZE // NUM_LABELS) + j, i] = 1.0\n",
    "\n",
    "label = torch.FloatTensor(batch_size)\n",
    "one_hot_labels = torch.FloatTensor(batch_size, 10)\n",
    "\n",
    "if cuda:\n",
    "    model_d.cuda()\n",
    "    model_g.cuda()\n",
    "    input, label = input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "    one_hot_labels = one_hot_labels.cuda()\n",
    "    fixed_labels = fixed_labels.cuda()\n",
    "\n",
    "optim_d = optim.SGD(model_d.parameters(), lr=lr)\n",
    "optim_g = optim.SGD(model_g.parameters(), lr=lr)\n",
    "fixed_noise = Variable(fixed_noise)\n",
    "fixed_labels = Variable(fixed_labels)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "for epoch_idx in range(epochs):\n",
    "    model_d.train()\n",
    "    model_g.train()\n",
    "\n",
    "\n",
    "    d_loss = 0.0\n",
    "    g_loss = 0.0\n",
    "    for batch_idx, (train_x, train_y) in enumerate(train_custom_data):\n",
    "        batch_size = train_x.size(0)\n",
    "        train_x = train_x.view(-1, INPUT_SIZE)\n",
    "        if cuda:\n",
    "            train_x = train_x.cuda()\n",
    "            train_y = train_y.cuda()\n",
    "\n",
    "        input.resize_as_(train_x).copy_(train_x)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "        one_hot_labels.resize_(batch_size, NUM_LABELS).zero_()\n",
    "        one_hot_labels.scatter_(1, train_y.view(batch_size,1), 1)\n",
    "        inputv = Variable(input)\n",
    "        labelv = Variable(label)\n",
    "\n",
    "        output = model_d(inputv, Variable(one_hot_labels))\n",
    "        optim_d.zero_grad()\n",
    "        errD_real = criterion(output, labelv)\n",
    "        errD_real.backward()\n",
    "        realD_mean = output.data.cpu().mean()\n",
    "\n",
    "        one_hot_labels.zero_()\n",
    "        rand_y = torch.from_numpy(\n",
    "            np.random.randint(0, NUM_LABELS, size=(batch_size,1))).cuda()\n",
    "        one_hot_labels.scatter_(1, rand_y.view(batch_size,1), 1)\n",
    "        noise.resize_(batch_size, nz).normal_(0,1)\n",
    "        label.resize_(batch_size).fill_(fake_label)\n",
    "        noisev = Variable(noise)\n",
    "        labelv = Variable(label)\n",
    "        onehotv = Variable(one_hot_labels)\n",
    "        g_out = model_g(noisev, onehotv)\n",
    "        output = model_d(g_out, onehotv)\n",
    "        errD_fake = criterion(output, labelv)\n",
    "        fakeD_mean = output.data.cpu().mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        errD_fake.backward()\n",
    "        optim_d.step()\n",
    "\n",
    "        # train the G\n",
    "        noise.normal_(0,1)\n",
    "        one_hot_labels.zero_()\n",
    "        rand_y = torch.from_numpy(\n",
    "            np.random.randint(0, NUM_LABELS, size=(batch_size,1))).cuda()\n",
    "        one_hot_labels.scatter_(1, rand_y.view(batch_size,1), 1)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "        onehotv = Variable(one_hot_labels)\n",
    "        noisev = Variable(noise)\n",
    "        labelv = Variable(label)\n",
    "        g_out = model_g(noisev, onehotv)\n",
    "        output = model_d(g_out, onehotv)\n",
    "        errG = criterion(output, labelv)\n",
    "        optim_g.zero_grad()\n",
    "        errG.backward()\n",
    "        optim_g.step()\n",
    "\n",
    "        d_loss += errD.data\n",
    "        g_loss += errG.data\n",
    "        if batch_idx % print_every == 0:\n",
    "            print(\n",
    "            \"\\t{} ({} / {}) mean D(fake) = {:.4f}, mean D(real) = {:.4f}\".\n",
    "                format(epoch_idx, batch_idx, len(train_loader), fakeD_mean,\n",
    "                    realD_mean))\n",
    "\n",
    "            g_out = model_g(fixed_noise, fixed_labels).data.view(\n",
    "                SAMPLE_SIZE, 1, 28,28).cpu()\n",
    "            save_image(g_out,\n",
    "                '{}/{}_{}+nine.png'.format(\n",
    "                    samples_dir, epoch_idx, batch_idx))\n",
    "\n",
    "\n",
    "    print('Epoch {} - D loss = {:.4f}, G loss = {:.4f}'.format(epoch_idx,\n",
    "        d_loss, g_loss))\n",
    "#     if epoch_idx % save_every == 0:\n",
    "#         torch.save(model_d.state_dict(),\n",
    "#                     '{}/model_d_epoch_{}.pkl'.format(\n",
    "#                         save_dir, epoch_idx))\n",
    "#         torch.save(model_g.state_dict(),\n",
    "#                     '{}/model_g_epoch_{}.pkl'.format(\n",
    "#                         save_dir, epoch_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "images = []\n",
    "for e in range(epochs-1):\n",
    "    img_name = 'samples/' + str(e + 1) + '_0+nine.png' \n",
    "    images.append(imageio.imread(img_name))\n",
    "imageio.mimsave('hahaha_generation_animation.gif', images, fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
