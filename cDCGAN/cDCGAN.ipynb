{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataloader import default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelD, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, 1, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, 1, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.fc1  = nn.Linear(64*28*28+1000, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1)\n",
    "        self.fc3 = nn.Linear(10, 1000)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, 1, 28,28)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(batch_size, 64*28*28)\n",
    "        y_ = self.fc3(labels)\n",
    "        y_ = F.relu(y_)\n",
    "        x = torch.cat([x, y_], 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "class ModelG(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        self.z_dim = z_dim\n",
    "        super(ModelG, self).__init__()\n",
    "        self.fc2 = nn.Linear(10, 1000)\n",
    "        self.fc = nn.Linear(self.z_dim+1000, 64*28*28)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.deconv1 = nn.ConvTranspose2d(64, 32, 5, 1, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.deconv2 = nn.ConvTranspose2d(32, 1, 5, 1, 2)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        batch_size = x.size(0)\n",
    "        y_ = self.fc2(labels)\n",
    "        y_ = F.relu(y_)\n",
    "        x = torch.cat([x, y_], 1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(batch_size, 64, 28, 28)\n",
    "        x = self.bn1(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.01\n",
    "epochs = 10\n",
    "nz = 100\n",
    "save_every = 1\n",
    "save_dir = 'models'\n",
    "samples_dir = 'samples'\n",
    "cuda = True\n",
    "print_every = 50\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "if not os.path.exists(samples_dir):\n",
    "    os.mkdir(samples_dir)\n",
    "\n",
    "INPUT_SIZE = 784\n",
    "SAMPLE_SIZE = 80\n",
    "NUM_LABELS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    modified_batch = []\n",
    "    for item in batch:\n",
    "        image, label = item\n",
    "        if label is not 9:\n",
    "            modified_batch.append(item)\n",
    "    return default_collate(modified_batch)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transform),\n",
    "                   batch_size=128, shuffle=True, collate_fn = my_collate)\n",
    "\n",
    "model_d = ModelD()\n",
    "model_g = ModelG(nz)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "input = torch.FloatTensor(batch_size, INPUT_SIZE)\n",
    "noise = torch.FloatTensor(batch_size, (nz))\n",
    "\n",
    "fixed_noise = torch.FloatTensor(SAMPLE_SIZE, nz).normal_(0,1)\n",
    "fixed_labels = torch.zeros(SAMPLE_SIZE, NUM_LABELS)\n",
    "\n",
    "for i in range(NUM_LABELS):\n",
    "    for j in range(SAMPLE_SIZE // NUM_LABELS):\n",
    "        fixed_labels[i*(SAMPLE_SIZE // NUM_LABELS) + j, i] = 1.0\n",
    "\n",
    "label = torch.FloatTensor(batch_size)\n",
    "one_hot_labels = torch.FloatTensor(batch_size, 10)\n",
    "\n",
    "if cuda:\n",
    "    model_d.cuda()\n",
    "    model_g.cuda()\n",
    "    input, label = input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "    one_hot_labels = one_hot_labels.cuda()\n",
    "    fixed_labels = fixed_labels.cuda()\n",
    "\n",
    "optim_d = optim.SGD(model_d.parameters(), lr=lr)\n",
    "optim_g = optim.SGD(model_g.parameters(), lr=lr)\n",
    "fixed_noise = Variable(fixed_noise)\n",
    "fixed_labels = Variable(fixed_labels)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "for epoch_idx in range(epochs):\n",
    "    model_d.train()\n",
    "    model_g.train()\n",
    "\n",
    "    d_loss = 0.0\n",
    "    g_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (train_x, train_y) in enumerate(train_loader):\n",
    "        batch_size = train_x.size(0)\n",
    "        train_x = train_x.view(-1, INPUT_SIZE)\n",
    "        if cuda:\n",
    "            train_x = train_x.cuda()\n",
    "            train_y = train_y.cuda()\n",
    "\n",
    "        input.resize_as_(train_x).copy_(train_x)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "        one_hot_labels.resize_(batch_size, NUM_LABELS).zero_()\n",
    "        one_hot_labels.scatter_(1, train_y.view(batch_size,1), 1)\n",
    "        inputv = Variable(input)\n",
    "        labelv = Variable(label)\n",
    "\n",
    "        output = model_d(inputv, Variable(one_hot_labels))\n",
    "        optim_d.zero_grad()\n",
    "        errD_real = criterion(output, labelv)\n",
    "        errD_real.backward()\n",
    "        realD_mean = output.data.cpu().mean()\n",
    "\n",
    "        one_hot_labels.zero_()\n",
    "        rand_y = torch.from_numpy(\n",
    "            np.random.randint(0, NUM_LABELS, size=(batch_size,1))).cuda()\n",
    "        one_hot_labels.scatter_(1, rand_y.view(batch_size,1), 1)\n",
    "        noise.resize_(batch_size, nz).normal_(0,1)\n",
    "        label.resize_(batch_size).fill_(fake_label)\n",
    "        noisev = Variable(noise)\n",
    "        labelv = Variable(label)\n",
    "        onehotv = Variable(one_hot_labels)\n",
    "        g_out = model_g(noisev, onehotv)\n",
    "        output = model_d(g_out, onehotv)\n",
    "        errD_fake = criterion(output, labelv)\n",
    "        fakeD_mean = output.data.cpu().mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        errD_fake.backward()\n",
    "        optim_d.step()\n",
    "\n",
    "        # train the G\n",
    "        noise.normal_(0,1)\n",
    "        one_hot_labels.zero_()\n",
    "        rand_y = torch.from_numpy(\n",
    "            np.random.randint(0, NUM_LABELS, size=(batch_size,1))).cuda()\n",
    "        one_hot_labels.scatter_(1, rand_y.view(batch_size,1), 1)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "        onehotv = Variable(one_hot_labels)\n",
    "        noisev = Variable(noise)\n",
    "        labelv = Variable(label)\n",
    "        g_out = model_g(noisev, onehotv)\n",
    "        output = model_d(g_out, onehotv)\n",
    "        errG = criterion(output, labelv)\n",
    "        optim_g.zero_grad()\n",
    "        errG.backward()\n",
    "        optim_g.step()\n",
    "\n",
    "        d_loss += errD.data\n",
    "        g_loss += errG.data\n",
    "        if batch_idx % print_every == 0:\n",
    "            print(\n",
    "            \"\\t{} ({} / {}) mean D(fake) = {:.4f}, mean D(real) = {:.4f}\".\n",
    "                format(epoch_idx, batch_idx, len(train_loader), fakeD_mean,\n",
    "                    realD_mean))\n",
    "\n",
    "            g_out = model_g(fixed_noise, fixed_labels).data.view(\n",
    "                SAMPLE_SIZE, 1, 28,28).cpu()\n",
    "            save_image(g_out,\n",
    "                '{}/{}_{}.png'.format(\n",
    "                    samples_dir, epoch_idx, batch_idx))\n",
    "\n",
    "\n",
    "    print('Epoch {} - D loss = {:.4f}, G loss = {:.4f}'.format(epoch_idx,\n",
    "        d_loss, g_loss))\n",
    "    if epoch_idx % save_every == 0:\n",
    "        torch.save(model_d.state_dict(),\n",
    "                    '{}/model_d_epoch_{}.pkl'.format(\n",
    "                        save_dir, epoch_idx))\n",
    "        torch.save(model_g.state_dict(),\n",
    "                    '{}/model_g_epoch_{}.pkl'.format(\n",
    "                        save_dir, epoch_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer-Learning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model = ModelG(100)\n",
    "g_model.load_state_dict(torch.load(\"models/model_g_epoch_9.pkl\"))\n",
    "g_model.eval()\n",
    "\n",
    "d_model = ModelD()\n",
    "d_model.load_state_dict(torch.load(\"models/model_d_epoch_9.pkl\"))\n",
    "d_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model.cuda()\n",
    "d_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing parameters\n",
    "batch_size = 1\n",
    "\n",
    "# Getting some images of nine ready for inference:\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='nine_data', train=True, download=True, transform=transform)\n",
    "\n",
    "idx = dataset.targets == 9\n",
    "\n",
    "dataset.data = dataset.data[idx]\n",
    "dataset.targets = dataset.targets[idx]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "print(type(train_iter))\n",
    "\n",
    "images, labels = train_iter.next()\n",
    "\n",
    "print('images shape on batch size = {}'.format(images.size()))\n",
    "print('labels shape on batch size = {}'.format(labels.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.title(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if train_loader is giving only nines\n",
    "print(type(train_loader))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for x_, y in train_loader:\n",
    "    count+= 1\n",
    "    # print(x_)\n",
    "    print(y)\n",
    "    if count == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data to be trained upon: around 200 images\n",
    "\n",
    "train_custom_data = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    count = 0\n",
    "    for item in train_loader:\n",
    "        train_custom_data.append(item)\n",
    "        count += 1\n",
    "        if count == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_custom_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.FloatTensor(batch_size, INPUT_SIZE)\n",
    "noise = torch.FloatTensor(batch_size, (nz))\n",
    "\n",
    "fixed_noise = torch.FloatTensor(SAMPLE_SIZE, nz).normal_(0,1)\n",
    "fixed_labels = torch.zeros(SAMPLE_SIZE, NUM_LABELS)\n",
    "\n",
    "for i in range(NUM_LABELS):\n",
    "    for j in range(SAMPLE_SIZE // NUM_LABELS):\n",
    "        fixed_labels[i*(SAMPLE_SIZE // NUM_LABELS) + j, i] = 1.0\n",
    "\n",
    "label = torch.FloatTensor(batch_size)\n",
    "one_hot_labels = torch.FloatTensor(batch_size, 10)\n",
    "\n",
    "if cuda:\n",
    "    model_d.cuda()\n",
    "    model_g.cuda()\n",
    "    input, label = input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "    one_hot_labels = one_hot_labels.cuda()\n",
    "    fixed_labels = fixed_labels.cuda()\n",
    "\n",
    "optim_d = optim.SGD(model_d.parameters(), lr=lr)\n",
    "optim_g = optim.SGD(model_g.parameters(), lr=lr)\n",
    "fixed_noise = Variable(fixed_noise)\n",
    "fixed_labels = Variable(fixed_labels)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "for epoch_idx in range(epochs):\n",
    "    model_d.train()\n",
    "    model_g.train()\n",
    "\n",
    "\n",
    "    d_loss = 0.0\n",
    "    g_loss = 0.0\n",
    "    for batch_idx, (train_x, train_y) in enumerate(train_custom_data):\n",
    "        batch_size = train_x.size(0)\n",
    "        train_x = train_x.view(-1, INPUT_SIZE)\n",
    "        if cuda:\n",
    "            train_x = train_x.cuda()\n",
    "            train_y = train_y.cuda()\n",
    "\n",
    "        input.resize_as_(train_x).copy_(train_x)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "        one_hot_labels.resize_(batch_size, NUM_LABELS).zero_()\n",
    "        one_hot_labels.scatter_(1, train_y.view(batch_size,1), 1)\n",
    "        inputv = Variable(input)\n",
    "        labelv = Variable(label)\n",
    "\n",
    "        output = model_d(inputv, Variable(one_hot_labels))\n",
    "        optim_d.zero_grad()\n",
    "        errD_real = criterion(output, labelv)\n",
    "        errD_real.backward()\n",
    "        realD_mean = output.data.cpu().mean()\n",
    "\n",
    "        one_hot_labels.zero_()\n",
    "        rand_y = torch.from_numpy(\n",
    "            np.random.randint(0, NUM_LABELS, size=(batch_size,1))).cuda()\n",
    "        one_hot_labels.scatter_(1, rand_y.view(batch_size,1), 1)\n",
    "        noise.resize_(batch_size, nz).normal_(0,1)\n",
    "        label.resize_(batch_size).fill_(fake_label)\n",
    "        noisev = Variable(noise)\n",
    "        labelv = Variable(label)\n",
    "        onehotv = Variable(one_hot_labels)\n",
    "        g_out = model_g(noisev, onehotv)\n",
    "        output = model_d(g_out, onehotv)\n",
    "        errD_fake = criterion(output, labelv)\n",
    "        fakeD_mean = output.data.cpu().mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        errD_fake.backward()\n",
    "        optim_d.step()\n",
    "\n",
    "        # train the G\n",
    "        noise.normal_(0,1)\n",
    "        one_hot_labels.zero_()\n",
    "        rand_y = torch.from_numpy(\n",
    "            np.random.randint(0, NUM_LABELS, size=(batch_size,1))).cuda()\n",
    "        one_hot_labels.scatter_(1, rand_y.view(batch_size,1), 1)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "        onehotv = Variable(one_hot_labels)\n",
    "        noisev = Variable(noise)\n",
    "        labelv = Variable(label)\n",
    "        g_out = model_g(noisev, onehotv)\n",
    "        output = model_d(g_out, onehotv)\n",
    "        errG = criterion(output, labelv)\n",
    "        optim_g.zero_grad()\n",
    "        errG.backward()\n",
    "        optim_g.step()\n",
    "\n",
    "        d_loss += errD.data\n",
    "        g_loss += errG.data\n",
    "        if batch_idx % print_every == 0:\n",
    "            print(\n",
    "            \"\\t{} ({} / {}) mean D(fake) = {:.4f}, mean D(real) = {:.4f}\".\n",
    "                format(epoch_idx, batch_idx, len(train_loader), fakeD_mean,\n",
    "                    realD_mean))\n",
    "\n",
    "            g_out = model_g(fixed_noise, fixed_labels).data.view(\n",
    "                SAMPLE_SIZE, 1, 28,28).cpu()\n",
    "            save_image(g_out,\n",
    "                '{}/{}_{}+nine.png'.format(\n",
    "                    samples_dir, epoch_idx, batch_idx))\n",
    "\n",
    "\n",
    "    print('Epoch {} - D loss = {:.4f}, G loss = {:.4f}'.format(epoch_idx,\n",
    "        d_loss, g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "images = []\n",
    "for e in range(epochs-1):\n",
    "    img_name = 'samples/' + str(e + 1) + '_0+nine.png' \n",
    "    images.append(imageio.imread(img_name))\n",
    "imageio.mimsave('hahaha_generation_animation.gif', images, fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
